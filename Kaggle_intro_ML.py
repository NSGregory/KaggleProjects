

# ****************************************************************************
#           Basic Pandas function: pull data out of the CSV file
#
# ****************************************************************************

import pandas as pd
heart_file = "heart.csv"
dataset = pd.read_csv(heart_file)

# ****************************************************************************
#       End Basic Pandas Function: Pull Data out of the CSV File
# ****************************************************************************

# ****************************************************************************
#
#            Splitting training and testing
#
# ****************************************************************************
# We need to divide up the data into a training set and a testing set, because
# if we test the model on the data we train it with, we will get "perfect"
# results that don't necessarily indicate how good the model actually is.

from sklearn.model_selection import train_test_split

# split data into training and validation data, for both features and target
# The split is based on a random number generator. Supplying a numeric value to
# the random_state argument guarantees we get the same split every time we
# run this script.
#
# train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)
#
# (implemented below)
# ****************************************************************************
#       End: Splitting Training and Testing
# ****************************************************************************



# ****************************************************************************
#
#           This Section for How to Define a Model Using
#                        Decision Tree Regressor
#
# ****************************************************************************
# This section establishes the model.  Features are the data within the model
# that will be used to predict the target value.  By convention it is labeled X.
# X will be a list of Series from within the original dataset.
#
#        X = original_dataset[List_Of_Column_Titles]
#
# The Target is the value we ultimately wish to predict.  When building the
# model, the target is a series.  By convention it is labeled y.
#
#        y = original_dataset.target
#
# ****************************************************************************
from sklearn.tree import DecisionTreeRegressor

dataset_features = ['age','sex','cp','trestbps','chol', 'fbs','restecg',
                    'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']
y = dataset.target
X = dataset[dataset_features]

# splits y and X into training and testing data
# (see above: Splitting Training and Testing)
train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)

heartDZ_model = DecisionTreeRegressor(random_state=5)
heartDZ_model.fit(train_X, train_y)

print("Decision tree regressor:",heartDZ_model.predict(val_X.head()))

# ****************************************************************************
#       End Building the DecisionTreeRegressor
# ****************************************************************************

# ****************************************************************************
#
#                   Mean Absolute Error
#
#   A tool for assessing how good the model is at predicting the correct value.
#
# For each entry in the dataframe, error can be defined as:
#
#          error = actual - predicted
#
# Mean absolute error is calculated by taking the absolute value of error for
# each of the predicted values generated by the model in the dataframe and then
# calculating the mean of those values.
# ****************************************************************************

from sklearn.metrics import mean_absolute_error

# ****************************************************************************

disease_prediction = heartDZ_model.predict(val_X)
error = mean_absolute_error(val_y, disease_prediction)
print(error)

# ****************************************************************************
# End Mean Absolute Error
# ****************************************************************************

# ****************************************************************************
#
#         mae_over_range_of_nodes
#
#     This function iterates MAE calculations for a Decision Tree Regressor
# over a user defined range of node number and prints the MAE for each node
# number.  It is intended as a teaching tool to understand the effects of
# overfitting and underfitting a model.
#
# Overfitting and underfitting refer to making the model fit too closely or
# too loosely to the training data.  A model that is overfit will hone in on
# features of the training data that don't represent actual factors found in the
# larger dataset.  As such, overfit models will very closely resemble the
# training data, but poorly predict outcomes. Underfit models will poorly fit
# both the training data and make poor predictions.
#
# Dependency: sklearn
# ****************************************************************************

def mae_over_range_of_nodes(max_leaf_nodes_range, train_X, val_X, train_y, val_y):
    """ This function is a teaching tool using the mean absolute error function
    from sklearn.  It is meant to help understand overfitting and underfitting.
    The dataset should be split using split_train function prior to calling this
    function."""
    tup_list = []
    for max_leaf_nodes in max_leaf_nodes_range:
        model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)
        model.fit(train_X, train_y)
        preds_val = model.predict(val_X)
        mae = mean_absolute_error(val_y, preds_val)
        tup_list.append((max_leaf_nodes, mae))
    min_mae_node_value = tup_list[0][0]
    min_mae = tup_list[0][1]
    for x in tup_list:
        if x[1] < min_mae:
            min_mae = x[1]
            min_node_value = x[0]
    print("These parameters resulted in: ")
    print(tup_list)
    print("The optimal node is", min_node_value, ". Which produced a MAE of", min_mae)

#example of calling this function
mae_over_range_of_nodes([5,10,25,125,626],train_X, val_X, train_y, val_y)

# ****************************************************************************
# End mae_over_range_of_nodes
# ****************************************************************************

# ****************************************************************************
#
#           This Section for How to Define a Model Using
#                        Decision Tree Regressor
#
# ****************************************************************************
# This section establishes the model.  Features are the data within the model
# that will be used to predict the target value.  By convention it is labeled X.
# X will be a list of Series from within the original dataset.
#
#        X = original_dataset[List_Of_Column_Titles]
#
# The Target is the value we ultimately wish to predict.  When building the
# model, the target is a series.  By convention it is labeled y.
#
#        y = original_dataset.target
#
# ****************************************************************************
from sklearn.ensemble import RandomForestRegressor

dataset_features = ['age','sex','cp','trestbps','chol', 'fbs','restecg',
                    'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']
y = dataset.target
X = dataset[dataset_features]

# splits y and X into training and testing data
# (see above: Splitting Training and Testing)
train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)

heartDZ_forest_model = RandomForestRegressor(random_state=5)
heartDZ_forest_model.fit(train_X, train_y)

print("Random Forest Regressor predictions:",
       heartDZ_forest_model.predict(val_X.head()))
print("Random Forest Regressor MAE:",
       mean_absolute_error(val_y, heartDZ_forest_model.predict(val_X)))

# ****************************************************************************
#       End Building the RandomForestRegressor
# ****************************************************************************
